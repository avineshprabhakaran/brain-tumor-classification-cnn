{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/avineshprabhakaran/cnn-project-with-pytorch-brain-tumor-dataset?scriptVersionId=280658950\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-11-21T15:46:40.273174Z","iopub.execute_input":"2025-11-21T15:46:40.27372Z","iopub.status.idle":"2025-11-21T15:46:46.800632Z","shell.execute_reply.started":"2025-11-21T15:46:40.273697Z","shell.execute_reply":"2025-11-21T15:46:46.799827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Importing Essential Libraries\n\nThe following libraries are imported to enable:\n- Building and training neural networks (PyTorch)\n- Data loading and augmentation (torchvision, DataLoader)\n- Visualization (matplotlib)\n","metadata":{}},{"cell_type":"code","source":"# PyTorch and required modules for deep learning and data handling\nimport torch\nfrom torch import nn, optim\n\n# TorchVision for popular datasets and image transformations\nfrom torchvision import datasets, transforms\n\n# DataLoader utility for batching and shuffling\nfrom torch.utils.data import DataLoader\n\n# Visualization library for plotting data and results\nimport matplotlib.pyplot as plt\n\n# Import ImageFolder for loading data from directories organized by class\nfrom torchvision.datasets import ImageFolder\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T16:03:47.550177Z","iopub.execute_input":"2025-11-21T16:03:47.550982Z","iopub.status.idle":"2025-11-21T16:03:52.866493Z","shell.execute_reply.started":"2025-11-21T16:03:47.550952Z","shell.execute_reply":"2025-11-21T16:03:52.865846Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Configuration & Hyperparameters\n\nSet up paths, batch size, class count, and learning parameters for the project.\n","metadata":{}},{"cell_type":"code","source":"# Path to the dataset directory (change as needed for your environment)\nroot = '/kaggle/input/brain-tumor-mri-dataset'\n\n# Subfolders for training and testing splits\ntrain, test = 'Training', 'Testing'\n\n# Batch size for data loading\nbatch_size = 32\n\n# Number of classes for classification \nnum_classes = 4\n\n# Learning rate for optimizer\nlearning_rate = 0.001\n\n# Number of training epochs\nepochs = 10\n","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-11-21T16:03:55.128909Z","iopub.execute_input":"2025-11-21T16:03:55.129392Z","iopub.status.idle":"2025-11-21T16:03:55.134Z","shell.execute_reply.started":"2025-11-21T16:03:55.129368Z","shell.execute_reply":"2025-11-21T16:03:55.133073Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Device Configuration\n\nSelect computation device (CPU or GPU) for efficient training.\n","metadata":{}},{"cell_type":"code","source":"# Automatically select GPU (cuda) if available, else fallback to CPU\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Display the current device being used for computation\nprint(f'Current Device: {device}.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T16:03:57.978571Z","iopub.execute_input":"2025-11-21T16:03:57.979415Z","iopub.status.idle":"2025-11-21T16:03:58.044325Z","shell.execute_reply.started":"2025-11-21T16:03:57.979386Z","shell.execute_reply":"2025-11-21T16:03:58.043486Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Transformations\n\nPreprocess the images by resizing and converting to tensors before feeding them into the neural network.\n","metadata":{}},{"cell_type":"code","source":"# Compose a series of image transformations for preprocessing\ntf = transforms.Compose([\n    # Resize all images to 128x128 pixels\n    transforms.Resize((128, 128)),\n    \n    # Convert images to PyTorch tensors (scales pixel values to [0,1])\n    transforms.ToTensor(),\n    \n    # (Optional) Normalize the tensors - uncomment if normalization is desired\n    # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T16:04:00.147305Z","iopub.execute_input":"2025-11-21T16:04:00.147772Z","iopub.status.idle":"2025-11-21T16:04:00.151654Z","shell.execute_reply.started":"2025-11-21T16:04:00.147745Z","shell.execute_reply":"2025-11-21T16:04:00.150958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''train_data = DataLoader(\n    datasets.ImageFolder('/kaggle/input/brain-tumor-mri-dataset/Training',tf),\n    batch_size=32,shuffle=True,num_workers=4,pin_memory=True\n)\n\ntest_data = DataLoader(\n    datasets.ImageFolder('/kaggle/input/brain-tumor-mri-dataset/Testing',tf),\n    batch_size=32,shuffle=False,num_workers=4,pin_memory=True\n)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T16:04:02.032969Z","iopub.execute_input":"2025-11-21T16:04:02.033545Z","iopub.status.idle":"2025-11-21T16:04:02.038961Z","shell.execute_reply.started":"2025-11-21T16:04:02.033523Z","shell.execute_reply":"2025-11-21T16:04:02.038202Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prepare Dataset and DataLoader Objects\n\nLoad images into PyTorch datasets using `ImageFolder`, and wrap with `DataLoader` for batching and shuffling during training and evaluation.\n","metadata":{}},{"cell_type":"code","source":"import os  # Don't forget to import if not already done!\n\n# Load training dataset using ImageFolder and apply preprocessing transforms\ntrain_data = ImageFolder(os.path.join(root, train), transform=tf)\n\n# Wrap training dataset with DataLoader for batching and shuffling\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n\n# Load testing dataset using ImageFolder and apply preprocessing transforms\ntest_data = ImageFolder(os.path.join(root, test), transform=tf)\n\n# Wrap test dataset with DataLoader for batching, no shuffling for evaluation\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n\n# Print summary of data loading process\nprint(f'Batch size: {batch_size}')\nprint(f'Found {len(train_data)} training images across {num_classes} classes.')\nprint(f'Found {len(test_data)} testing images across {num_classes} classes.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T16:04:02.924026Z","iopub.execute_input":"2025-11-21T16:04:02.924309Z","iopub.status.idle":"2025-11-21T16:04:12.287843Z","shell.execute_reply.started":"2025-11-21T16:04:02.924289Z","shell.execute_reply":"2025-11-21T16:04:12.287197Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize Sample Images from the Training Dataset\n\nDisplay a grid of sample images along with their class labels to verify dataset integrity and provide an overview of the input data.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np  # Add this import if not already done\n\n# Get a batch of images and labels from the training DataLoader\ndata_iter = iter(train_loader)\nimages, labels = next(data_iter)\n\n# Define mean and std for un-normalizing (common for pretrained models, adjust if custom normalization is used)\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\n\n# Convert images from tensors to numpy arrays and un-normalize for proper visualization\nimages = (images.numpy().transpose((0, 2, 3, 1)) * std + mean).clip(0, 1)\n\n# Set grid dimensions: up to 16 images, in 4 rows\nnum_images = min(len(images), 16)\nrows = 4\nfig, axes = plt.subplots(rows, 4, figsize=(15, 4 * rows))\n\nfor i, ax in enumerate(axes.flat):\n    if i < num_images:\n        ax.imshow(images[i])\n        ax.set_title(f'Label: {train_data.classes[labels[i]]}', fontsize=15, fontweight='bold')\n        ax.axis('off')\n\n# Hide unused subplots if batch size < grid size\nfor ax in axes.flat[num_images:]:\n    ax.axis('off')\n\nplt.tight_layout(pad=1)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T16:04:15.7405Z","iopub.execute_input":"2025-11-21T16:04:15.741101Z","iopub.status.idle":"2025-11-21T16:04:18.017324Z","shell.execute_reply.started":"2025-11-21T16:04:15.741068Z","shell.execute_reply":"2025-11-21T16:04:18.016218Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Architecture: Brain Tumor Classifier (Custom CNN)\n\nDefine a Convolutional Neural Network (CNN) using PyTorch for multi-class classification of brain tumor MRI images. The architecture includes convolutional layers for feature extraction and fully connected layers for classification.\n","metadata":{}},{"cell_type":"code","source":"# Define a custom CNN model for brain tumor classification\nclass BrainTumorClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(BrainTumorClassifier, self).__init__()\n        \n        # Feature extraction: three convolutional blocks (Conv + ReLU + MaxPool)\n        self.feature_layers = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=4, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3),\n\n            nn.Conv2d(32, 64, kernel_size=4, padding=1),\n            nn.ReLU(inplace=False),\n            nn.MaxPool2d(kernel_size=3),\n\n            nn.Conv2d(64, 128, kernel_size=4, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3)\n        )\n\n        self.flatten = nn.Flatten()  # Flatten feature map for dense layers\n\n        # Fully connected layers for classification\n        self.dense_layers = nn.Sequential(\n            nn.Linear(2048, 512),   # Adjust input size as per feature map output\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.feature_layers(x)\n        # Optional: print shape for debugging (uncomment if needed)\n        # print('Shape before flatten:', x.shape)\n        x = self.flatten(x)\n        # print('Shape after flatten:', x.shape)\n        x = self.dense_layers(x)\n        return x\n\n# Instantiate model, move to device (GPU/CPU)\nmodel = BrainTumorClassifier(num_classes=len(train_data.classes)).to(device)\n\n# Set loss function for multi-class classification\ncriterion = nn.CrossEntropyLoss()\n\n# Adam optimizer for training\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Print a summary of the model architecture\nprint(model)\n","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-11-21T16:04:26.313524Z","iopub.execute_input":"2025-11-21T16:04:26.314525Z","iopub.status.idle":"2025-11-21T16:04:26.497716Z","shell.execute_reply.started":"2025-11-21T16:04:26.314497Z","shell.execute_reply":"2025-11-21T16:04:26.497074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Training Loop\n\nTrain the CNN model for multiple epochs on the training dataset, optimizing the model parameters using the Adam optimizer and reporting the loss after each epoch.\n","metadata":{}},{"cell_type":"code","source":"# Set model to training mode (enables dropout/batchnorm if used)\nmodel.train()\n\n# Training loop: iterate for the specified number of epochs\nfor epoch in range(epochs):\n    running_loss = 0.0  # Track cumulative loss for the epoch\n\n    # Loop over each batch in the training dataset\n    for images, labels in train_loader:\n        # Move data to selected device (CPU or GPU)\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()  # Reset parameter gradients\n        \n        # Forward pass: compute model outputs, then calculate loss\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backpropagation: compute gradients\n        loss.backward()\n        \n        # Update model weights\n        optimizer.step()\n        \n        # Accumulate loss\n        running_loss += loss.item()\n    \n    # Calculate average loss for the epoch\n    avg_loss = running_loss / len(train_loader)\n    print(f'Epoch {epoch+1}/{epochs}: Average Loss = {avg_loss:.4f}')\n","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-11-21T16:04:31.472115Z","iopub.execute_input":"2025-11-21T16:04:31.472857Z","iopub.status.idle":"2025-11-21T16:09:09.51602Z","shell.execute_reply.started":"2025-11-21T16:04:31.472816Z","shell.execute_reply":"2025-11-21T16:09:09.515218Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation on Test Data\n\nEvaluate the trained CNN model on the test dataset. Compute the average test loss and overall accuracy to assess model performance.\n","metadata":{}},{"cell_type":"code","source":"# Set the model to evaluation mode (disables dropout/batchnorm)\nmodel.eval()\n\ntest_loss = 0.0  # Track total test loss\ncorrect = 0      # Track number of correct predictions\n\nwith torch.no_grad():  # No gradient computation needed during evaluation\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        logits = model(images)  # Forward pass\n        # Accumulate loss; multiply by batch size for correct averaging later\n        test_loss += criterion(logits, labels).item() * labels.size(0)\n        \n        # Get predicted class (highest logit) for each sample\n        preds = logits.argmax(dim=1)\n        # Count how many predictions match the true label\n        correct += (preds == labels).sum().item()\n\n# Average test loss over all samples\ntest_loss /= len(test_loader.dataset)\n# Compute accuracy as percentage of correct predictions\naccuracy = 100.0 * correct / len(test_loader.dataset)\n\nprint(f'Test Loss: {test_loss:.4f}   Test Accuracy: {accuracy:.2f}%')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T16:09:16.31179Z","iopub.execute_input":"2025-11-21T16:09:16.312474Z","iopub.status.idle":"2025-11-21T16:09:29.618646Z","shell.execute_reply.started":"2025-11-21T16:09:16.312449Z","shell.execute_reply":"2025-11-21T16:09:29.617865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize Random Test Images with Model Predictions\n\nDisplay random test samples along with their predicted and true class labels to visually assess model performance and spot-check inference results.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Select N sample predictions, e.g., 16\nN = 16\nindices = np.random.choice(len(test_loader.dataset), N, replace=False)\nplt.figure(figsize=(16,8))\nfor i, idx in enumerate(indices):\n    img, true_label = test_loader.dataset[idx]\n    img_disp = img * 0.5 + 0.5  # unnormalize if needed\n    pred = model(img.unsqueeze(0).to(device)).argmax(1).item()\n    plt.subplot(2, 8, i+1)\n    plt.imshow(to_pil_image(img_disp))\n    color = \"green\" if pred == true_label else \"red\"\n    plt.title(f\"P: {class_names[pred]}\\nT: {class_names[true_label]}\", color=color)\n    plt.axis(\"off\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T16:13:39.540199Z","iopub.execute_input":"2025-11-21T16:13:39.540453Z","iopub.status.idle":"2025-11-21T16:13:40.611666Z","shell.execute_reply.started":"2025-11-21T16:13:39.540437Z","shell.execute_reply":"2025-11-21T16:13:40.610797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}